{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on MCU - Exercise 2\n",
    "\n",
    "# Feature Extraction & Regularization in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def generate_data(lowest, highest, amount):\n",
    "    x = np.linspace(lowest, highest, num=amount)\n",
    "    y = []\n",
    "    noise = 400\n",
    "    random.seed(123)\n",
    "\n",
    "    for p in x:\n",
    "        y.append(10 + 0.5*p - 0.04*p**2 - 0.002*p**3 + 0.0003*p**4 - 0.00001*p**5 + random.randint(-noise,noise)/100)\n",
    "  \n",
    "    return x, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate some data based on parameters\n",
    "lowest = 10\n",
    "highest = 20\n",
    "amount = 200\n",
    "\n",
    "x, y = generate_data(lowest, highest, amount)\n",
    "\n",
    "# Do the regression while plotting\n",
    "models = []\n",
    "degrees = [1, 4, 5, 6, 10]\n",
    "\n",
    "line = np.linspace(lowest, highest, 100)\n",
    "\n",
    "\n",
    "for i, deg in enumerate(degrees):\n",
    "    plt.scatter(x, y, label = \"Data\", color='red', alpha=0.5)\n",
    "    plt.title(\"Polynomial Regression\")\n",
    "    p, residuals, rank, singular_values, rcond = np.polyfit(x, y, deg, full=True)\n",
    "    print(residuals)\n",
    "    models.append(np.poly1d(p))\n",
    "    plt.plot(line, models[i](line), label = \"Order n=\"+str(deg))\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "\n",
    "# Generate data based on new parameters\n",
    "lowest = 8 \n",
    "highest = 22\n",
    "amount = 25\n",
    "\n",
    "line = np.linspace(lowest, highest, 100)\n",
    "x, y = generate_data(lowest, highest, amount)\n",
    "\n",
    "# Plot without fitting to see how the models generalize\n",
    "for i, deg in enumerate(degrees):\n",
    "    plt.title(\"Polynomial Regression\")\n",
    "    plt.scatter(x, y, label = \"Data\", color='red', alpha=0.5)\n",
    "    plt.plot(line, models[i](line), label = \"Order n=\"+str(deg))\n",
    "    plt.legend()\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(f'Your tensorflow version is {tf.__version__}')\n",
    "print(f'Your numpy version is {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_lists(x, y):\n",
    "    data = list(zip(x, y))\n",
    "    random.shuffle(data)\n",
    "    x, y = zip(*data)\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x, y\n",
    "\n",
    "def normalize_data(data):\n",
    "    mean = np.mean(data)\n",
    "    dev = np.std(data)\n",
    "    return (data - mean) / dev, mean, dev\n",
    "\n",
    "def generate_data(lowest, highest, amount):\n",
    "    x = np.linspace(lowest, highest, num=amount)\n",
    "    y = []\n",
    "    noise = 1000\n",
    "    random.seed(123)\n",
    "\n",
    "    for p in x:\n",
    "        y.append(10 + 0.5*p - 0.04*p**2 + 0.002*p**3 + 0.0003*p**4 - 0.00001*p**5 + random.randint(-noise,noise)/100)\n",
    "  \n",
    "    return x, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "# Model configuration\n",
    "dropout   = False\n",
    "batchnorm = False\n",
    "normalize = False\n",
    "use_l1 = False\n",
    "use_l2 = False\n",
    "\n",
    "# Regularization parameters (tuning knobs)\n",
    "reg_l1_value = 0.0001  # L1 regularization factor\n",
    "reg_l2_value = 0.0001  # L2 regularization factor\n",
    "\n",
    "batch_size = 16\n",
    "no_epochs = 100\n",
    "optimizer = Adam()\n",
    "validation_split = 0.1\n",
    "plot_name = \"plot_default.pdf\"\n",
    "\n",
    "# Set regularization values according to the toggles\n",
    "reg_l1 = reg_l1_value if use_l1 else 0.0\n",
    "reg_l2 = reg_l2_value if use_l2 else 0.0\n",
    "\n",
    "\n",
    "def custom_activation(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "# Regularization techniques\n",
    "if dropout:\n",
    "    dropout_rate = 0.2\n",
    "    plot_name = \"plot_dropout.pdf\"\n",
    "if batchnorm:\n",
    "    plot_name = \"plot_batchnorm.pdf\"\n",
    "\n",
    "# Generate data\n",
    "dataset_size = 100\n",
    "\n",
    "# Ensure generate_data and shuffle_lists functions are defined and return NumPy arrays\n",
    "x, y = generate_data(10, 20, dataset_size)\n",
    "input_train, target_train =  shuffle_lists(x, y)\n",
    "\n",
    "validation_size = 50\n",
    "x, y = generate_data(8, 22, validation_size)\n",
    "input_test, target_test =  shuffle_lists(x, y)\n",
    "\n",
    "if normalize:\n",
    "    input_train, mean_in, dev_in = normalize_data(input_train)\n",
    "    target_train, mean_tar, dev_tar = normalize_data(target_train)\n",
    "    input_test = (input_test - mean_in) / dev_in\n",
    "    target_test = (target_test - mean_tar) / dev_tar\n",
    "\n",
    "input_train  = input_train.reshape(len(input_train), 1)\n",
    "target_train = target_train.reshape(len(target_train), 1)\n",
    "input_test   = input_test.reshape(len(input_test), 1)\n",
    "target_test  = target_test.reshape(len(target_test), 1)\n",
    "\n",
    "input_train = input_train.astype(np.float32)\n",
    "target_train = target_train.astype(np.float32)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(16,\n",
    "                activation=custom_activation,\n",
    "                input_dim=1,\n",
    "                kernel_regularizer=l1_l2(reg_l1, reg_l2)))\n",
    "model.add(Dense(512,\n",
    "                activation='elu',\n",
    "                kernel_regularizer=l1_l2(reg_l1, reg_l2)))\n",
    "if dropout:\n",
    "    model.add(Dropout(dropout_rate))\n",
    "if batchnorm:\n",
    "    model.add(BatchNormalization())\n",
    "model.add(Dense(1,\n",
    "                activation='elu',\n",
    "                kernel_regularizer=l1_l2(reg_l1, reg_l2)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=MeanSquaredError(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# Fit model to data\n",
    "set_seed(123)\n",
    "history = model.fit(input_train,\n",
    "                    target_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    verbose=True,\n",
    "                    validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "\n",
    "# Visualize history\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "# Plot loss history\n",
    "ax[0].plot(history.history['loss'], label='Training')\n",
    "ax[0].plot(history.history['val_loss'], label='Validation')\n",
    "ax[0].set_title('Loss History')\n",
    "ax[0].set_ylabel('Value')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot predictions\n",
    "if normalize:\n",
    "    linspace = np.linspace(-2.5, 2.5, 100)\n",
    "else:\n",
    "    linspace = np.linspace(8, 22, 100)\n",
    "\n",
    "linspace = linspace.reshape(-1, 1)\n",
    "\n",
    "pred = model.predict(linspace)\n",
    "ax[1].scatter(input_test, target_test, label='Data', color='red', alpha=0.5)\n",
    "ax[1].plot(linspace, pred, label='Model')\n",
    "ax[1].set_title('Predictions')\n",
    "ax[1].legend()\n",
    "\n",
    "# Save plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Audio Feature Extraction\n",
    "\n",
    "In this Notebook, we provide an example on how to:\n",
    "\n",
    "- Load an audio file stored in your PC\n",
    "- Visualize it\n",
    "- Extract its MFCCs\n",
    "\n",
    "This is an example of feature extraction.\n",
    "\n",
    "To complete this exercise, you need for a *wav* file. You can download one from here: https://freewavesamples.com/files/Ensoniq-ZR-76-01-Dope-77.wav\n",
    "\n",
    "First of all, we import the useful modules we need. If something goes wrong, you need to download and install the required packages first (use Anaconda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the audio into our program. Set the correct path to your *wav* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/PATH/TO/AUDIO.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_path, sr=44100, duration=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of samples... but how many? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of samples: ' + str(np.size(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also play the audio and bother the other people with annoying loud sounds! Super fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use *librosa* to visualize the audio track. We need the samples and the sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(y, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform *feature extraction* to reduce the amount of data to process next. \n",
    "\n",
    "To do so, let's extract the MFCCs for this audio; using the default parameters of librosa's function, we will end up with 20 MFCCs per audio's frame. \n",
    "*librosa* will take care of the division in frames, analysis and MFCCs extraction.\n",
    "\n",
    "> Notes on MFCCs extraction:\n",
    "> - The original audio signal is divided into overlapping frames, and for each frame, a set of MFCCs is computed.\n",
    "> - MFCCs are a compact representation of the short-term spectral envelope of a sound. MFCCs of one audio's frame are a vector of coefficients that describe the spectral features of a short segment of audio (audio frame).\n",
    "> - MFCCs are derived from the Mel scale, which is a perceptual scale of pitches that approximates the human ear's response to different frequencies.\n",
    "> - The Mel scale is designed to be more sensitive to lower frequencies and less sensitive to higher frequencies, which aligns with how humans perceive sound.\n",
    "> - MFCCs are widely used in various audio processing tasks, including speech recognition, music information retrieval..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 20 coefficients per frame. Let's see how many frames we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "print('(#MFCCs, #frames): ' + str(mfccs.shape))\n",
    "print('Total number of MFCCs: ' + str(np.size(mfccs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have {} frames with {} MFCCs each. Not bad!'.format(mfccs.shape[1], mfccs.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's plot them... We guess they are super-cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This MFCC visualization shows how the MFCCs (cepstral coefficients) vary over time (frames). MFCCs on the bottom generally represent lower frequencies features (spectral shape), while those on the top represent higher frequencies features.\n",
    "\n",
    "Go back to the audio signal: can you see how the MFCCs change when the audio signal amplitude changes? \n",
    "1. Within each frame: Dark blue and dark red areas in the MFCC plot correspond to strong presence of certain frequency components in the audio signal, which is prominently visible in the bottom part of the MFCC plot. This gives us a hint that the original audio signal is dominated by low tones. \n",
    "2. Across frames: We can see rapid changes in the audio signal, which is reflected in the MFCC plot as sharp change of color instead of smooth transitions. This gives a hint that the original audio signal has fast attacks.\n",
    "\n",
    "MFCC extraction helps us to capture the essential spectral characteristics of the audio signal while reducing the amount of data we need to process. This is particularly useful in machine learning applications where we want to analyze and classify audio signals efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our fresh MFCCs are ready to be processed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
